rag:
  llm: 
    llm_name: "mosaicml/mpt-7b"
    base_url: "http://localhost:8000/v1"
    max_new_tokens: 100
  retriever:
    db:
      uri: ./examples/index/llamavision/ner.db
    hybrid_search_weight: 0.5
    k: 5
  system_prompt: "Use the following context to answer the questions.\n\nContext:\n{context}"
mode: local
mode_args:
  input_file: ./examples/rag/queries.jsonl
  output_file: ./examples/rag/vllm/output.jsonl